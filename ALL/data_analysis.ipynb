{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>BMAN60422</b> - Data Analytics </br>\n",
    "## Developing A Credit Scoring Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter notebook investigates the data.csv file that is provided to make decisions about classifying applications for unsecured loans.\n",
    "\n",
    "Each chapter in this notebook saves their relative results (graphs, figures, tables etc.) into their respective directory inside the analytics folder that the script creates.\n",
    "\n",
    "The titles with light blue colour to them have code cells below them.\n",
    "\n",
    "---\n",
    "Author: Ozgur Aziz - 10860809"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:lightblue\">Loading Everything</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (5960, 13)\n",
      "Number of rows: 5960\n",
      "Number of columns: 13\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Create analytics folder\n",
    "if not os.path.exists('analytics'):\n",
    "    os.makedirs('analytics')\n",
    "\n",
    "output_dirs = ['chapter1', 'chapter2', 'chapter3', 'chapter4', 'chapter5']\n",
    "for dir_name in output_dirs:\n",
    "    if not os.path.exists(f'analytics/{dir_name}'):\n",
    "        os.makedirs(f'analytics/{dir_name}')\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Dictionary with column descriptions\n",
    "column_descriptions = {\n",
    "    'BAD': 'Loan Default Status (0: paid, 1: defaulted)',\n",
    "    'LOAN': 'Loan Amount Requested',\n",
    "    'MORTDUE': 'Amount Due on Existing Mortgage',\n",
    "    'VALUE': 'Value of Current Property',\n",
    "    'REASON': 'Loan Purpose (DebtCon: debt consolidation, HomeImp: home improvement)',\n",
    "    'JOB': 'Occupation Category',\n",
    "    'YOJ': 'Years at Present Job',\n",
    "    'DEROG': 'Number of Major Derogatory Reports',\n",
    "    'DELINQ': 'Number of Delinquent Credit Lines',\n",
    "    'CLAGE': 'Age of Oldest Credit Line in Months',\n",
    "    'NINQ': 'Number of Recent Credit Inquiries',\n",
    "    'CLNO': 'Number of Credit Lines',\n",
    "    'DEBTINC': 'Debt-to-Income Ratio'\n",
    "}\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Display data shape\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(f\"Number of rows: {data.shape[0]}\")\n",
    "print(f\"Number of columns: {data.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1\n",
    "\n",
    "<span style=\"color:red\">Future Works for Chapter 1:</span>\n",
    "* Advanced outlier detection techniques like <b>Isolation Forest or DBSCAN</b></br>\n",
    "* <b>Data quality scores</b> to quantify data completeness and reliability</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue\">Initial Data Exploring</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5960 entries, 0 to 5959\n",
      "Data columns (total 13 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   BAD      5960 non-null   int64  \n",
      " 1   LOAN     5960 non-null   int64  \n",
      " 2   MORTDUE  5442 non-null   float64\n",
      " 3   VALUE    5848 non-null   float64\n",
      " 4   REASON   5708 non-null   object \n",
      " 5   JOB      5681 non-null   object \n",
      " 6   YOJ      5445 non-null   float64\n",
      " 7   DEROG    5252 non-null   float64\n",
      " 8   DELINQ   5380 non-null   float64\n",
      " 9   CLAGE    5652 non-null   float64\n",
      " 10  NINQ     5450 non-null   float64\n",
      " 11  CLNO     5738 non-null   float64\n",
      " 12  DEBTINC  4693 non-null   float64\n",
      "dtypes: float64(9), int64(2), object(2)\n",
      "memory usage: 605.4+ KB\n",
      "None\n",
      "\n",
      "Descriptive statistics:\n",
      "               BAD          LOAN        MORTDUE          VALUE          YOJ  \\\n",
      "count  5960.000000   5960.000000    5442.000000    5848.000000  5445.000000   \n",
      "mean      0.199497  18607.969799   73760.817200  101776.048741     8.922268   \n",
      "std       0.399656  11207.480417   44457.609458   57385.775334     7.573982   \n",
      "min       0.000000   1100.000000    2063.000000    8000.000000     0.000000   \n",
      "25%       0.000000  11100.000000   46276.000000   66075.500000     3.000000   \n",
      "50%       0.000000  16300.000000   65019.000000   89235.500000     7.000000   \n",
      "75%       0.000000  23300.000000   91488.000000  119824.250000    13.000000   \n",
      "max       1.000000  89900.000000  399550.000000  855909.000000    41.000000   \n",
      "\n",
      "             DEROG       DELINQ        CLAGE         NINQ         CLNO  \\\n",
      "count  5252.000000  5380.000000  5652.000000  5450.000000  5738.000000   \n",
      "mean      0.254570     0.449442   179.766275     1.186055    21.296096   \n",
      "std       0.846047     1.127266    85.810092     1.728675    10.138933   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000   115.116702     0.000000    15.000000   \n",
      "50%       0.000000     0.000000   173.466667     1.000000    20.000000   \n",
      "75%       0.000000     0.000000   231.562278     2.000000    26.000000   \n",
      "max      10.000000    15.000000  1168.233561    17.000000    71.000000   \n",
      "\n",
      "           DEBTINC  \n",
      "count  4693.000000  \n",
      "mean     33.779915  \n",
      "std       8.601746  \n",
      "min       0.524499  \n",
      "25%      29.140031  \n",
      "50%      34.818262  \n",
      "75%      39.003141  \n",
      "max     203.312149  \n",
      "\n",
      "Missing values per column:\n",
      "BAD           0\n",
      "LOAN          0\n",
      "MORTDUE     518\n",
      "VALUE       112\n",
      "REASON      252\n",
      "JOB         279\n",
      "YOJ         515\n",
      "DEROG       708\n",
      "DELINQ      580\n",
      "CLAGE       308\n",
      "NINQ        510\n",
      "CLNO        222\n",
      "DEBTINC    1267\n",
      "dtype: int64\n",
      "\n",
      "Missing values percentage:\n",
      "BAD         0.000000\n",
      "LOAN        0.000000\n",
      "MORTDUE     8.691275\n",
      "VALUE       1.879195\n",
      "REASON      4.228188\n",
      "JOB         4.681208\n",
      "YOJ         8.640940\n",
      "DEROG      11.879195\n",
      "DELINQ      9.731544\n",
      "CLAGE       5.167785\n",
      "NINQ        8.557047\n",
      "CLNO        3.724832\n",
      "DEBTINC    21.258389\n",
      "dtype: float64\n",
      "Missing values visualization saved to 'analytics/chapter1/missing_values.png'\n"
     ]
    }
   ],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"Data Information:\")\n",
    "print(data.info())\n",
    "\n",
    "print('\\nDescriptive statistics:')\n",
    "print(data.describe())\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "missing_percentage = (missing_values / len(data)) * 100\n",
    "\n",
    "print('\\nMissing values per column:')\n",
    "print(missing_values)\n",
    "\n",
    "print('\\nMissing values percentage:')\n",
    "print(missing_percentage)\n",
    "\n",
    "# Save missing values plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "missing_percentage.plot(kind='bar')\n",
    "plt.title('Percentage of Missing Values by Column')\n",
    "plt.ylabel('Missing Values (%)')\n",
    "plt.xlabel('Columns')\n",
    "plt.tight_layout()\n",
    "plt.savefig('analytics/chapter1/missing_values.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Missing values visualization saved to 'analytics/chapter1/missing_values.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue\">Looking at Target Variables</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Variable Distribution:\n",
      "Class 0 (Good loans): 4771 (80.05%)\n",
      "Class 1 (Bad loans): 1189 (19.95%)\n",
      "Class imbalance ratio: 1:4.01\n",
      "Target distribution visualization saved to 'analytics/chapter1/target_distribution.png'\n"
     ]
    }
   ],
   "source": [
    "# Visualize the distribution of the target variable\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.countplot(x='BAD', data=data)\n",
    "plt.title('Distribution of Target Variable: ' + column_descriptions['BAD'])\n",
    "plt.xlabel(column_descriptions['BAD'])\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Add percentages on top of bars\n",
    "total = len(data)\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x() + p.get_width()/2., height + 0.1,\n",
    "            '{:1.2f}%'.format(height/total*100),\n",
    "            ha=\"center\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('analytics/chapter1/target_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# Calculate and print class distribution\n",
    "class_counts = data['BAD'].value_counts()\n",
    "class_percentages = class_counts / len(data) * 100\n",
    "\n",
    "print(\"Target Variable Distribution:\")\n",
    "print(f\"Class 0 (Good loans): {class_counts[0]} ({class_percentages[0]:.2f}%)\")\n",
    "print(f\"Class 1 (Bad loans): {class_counts[1]} ({class_percentages[1]:.2f}%)\")\n",
    "print(f\"Class imbalance ratio: 1:{class_counts[0]/class_counts[1]:.2f}\")\n",
    "print(\"Target distribution visualization saved to 'analytics/chapter1/target_distribution.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2\n",
    "\n",
    "<span style=\"color:red\">Future Works for Chapter 2:</span>\n",
    "* Create interaction features between strongly correlated variables</br>\n",
    "* Apply feature engineering to create more meaningful variables (loan-to-value ratio, etc.)</br>\n",
    "* Use statistical tests to more rigorously identify significant predictors</br>\n",
    "* Apply non-linear transformations to improve feature distributions</br>\n",
    "* Implement feature selection techniques like <b>RFE or LASSO</b> to reduce dimensionality</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue\">Numeric Features Analysis</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric Features Summary Statistics:\n",
      "\n",
      "LOAN: Loan Amount Requested\n",
      "count     5960.000000\n",
      "mean     18607.969799\n",
      "std      11207.480417\n",
      "min       1100.000000\n",
      "25%      11100.000000\n",
      "50%      16300.000000\n",
      "75%      23300.000000\n",
      "max      89900.000000\n",
      "Name: LOAN, dtype: float64\n",
      "\n",
      "MORTDUE: Amount Due on Existing Mortgage\n",
      "count      5442.000000\n",
      "mean      73760.817200\n",
      "std       44457.609458\n",
      "min        2063.000000\n",
      "25%       46276.000000\n",
      "50%       65019.000000\n",
      "75%       91488.000000\n",
      "max      399550.000000\n",
      "Name: MORTDUE, dtype: float64\n",
      "\n",
      "VALUE: Value of Current Property\n",
      "count      5848.000000\n",
      "mean     101776.048741\n",
      "std       57385.775334\n",
      "min        8000.000000\n",
      "25%       66075.500000\n",
      "50%       89235.500000\n",
      "75%      119824.250000\n",
      "max      855909.000000\n",
      "Name: VALUE, dtype: float64\n",
      "\n",
      "YOJ: Years at Present Job\n",
      "count    5445.000000\n",
      "mean        8.922268\n",
      "std         7.573982\n",
      "min         0.000000\n",
      "25%         3.000000\n",
      "50%         7.000000\n",
      "75%        13.000000\n",
      "max        41.000000\n",
      "Name: YOJ, dtype: float64\n",
      "\n",
      "DEROG: Number of Major Derogatory Reports\n",
      "count    5252.000000\n",
      "mean        0.254570\n",
      "std         0.846047\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         0.000000\n",
      "max        10.000000\n",
      "Name: DEROG, dtype: float64\n",
      "\n",
      "DELINQ: Number of Delinquent Credit Lines\n",
      "count    5380.000000\n",
      "mean        0.449442\n",
      "std         1.127266\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         0.000000\n",
      "max        15.000000\n",
      "Name: DELINQ, dtype: float64\n",
      "\n",
      "CLAGE: Age of Oldest Credit Line in Months\n",
      "count    5652.000000\n",
      "mean      179.766275\n",
      "std        85.810092\n",
      "min         0.000000\n",
      "25%       115.116702\n",
      "50%       173.466667\n",
      "75%       231.562278\n",
      "max      1168.233561\n",
      "Name: CLAGE, dtype: float64\n",
      "\n",
      "NINQ: Number of Recent Credit Inquiries\n",
      "count    5450.000000\n",
      "mean        1.186055\n",
      "std         1.728675\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         1.000000\n",
      "75%         2.000000\n",
      "max        17.000000\n",
      "Name: NINQ, dtype: float64\n",
      "\n",
      "CLNO: Number of Credit Lines\n",
      "count    5738.000000\n",
      "mean       21.296096\n",
      "std        10.138933\n",
      "min         0.000000\n",
      "25%        15.000000\n",
      "50%        20.000000\n",
      "75%        26.000000\n",
      "max        71.000000\n",
      "Name: CLNO, dtype: float64\n",
      "\n",
      "DEBTINC: Debt-to-Income Ratio\n",
      "count    4693.000000\n",
      "mean       33.779915\n",
      "std         8.601746\n",
      "min         0.524499\n",
      "25%        29.140031\n",
      "50%        34.818262\n",
      "75%        39.003141\n",
      "max       203.312149\n",
      "Name: DEBTINC, dtype: float64\n",
      "Visualizations for 10 numeric features saved to 'analytics/chapter2/' directory\n"
     ]
    }
   ],
   "source": [
    "# Get numeric columns\n",
    "numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "numeric_cols = [col for col in numeric_cols if col != 'BAD']\n",
    "\n",
    "# Print basic statistics for numeric features\n",
    "print(\"Numeric Features Summary Statistics:\")\n",
    "for col in numeric_cols:\n",
    "    print(f\"\\n{col}: {column_descriptions.get(col, col)}\")\n",
    "    print(data[col].describe())\n",
    "    \n",
    "    # Generate histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(data[col].dropna(), kde=True)\n",
    "    plt.title(f'Distribution of {col}: {column_descriptions.get(col, col)}')\n",
    "    plt.xlabel(column_descriptions.get(col, col))\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'analytics/chapter2/distribution_{col}.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Generate boxplot by target\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x='BAD', y=col, data=data)\n",
    "    plt.title(f'{col} by Target: {column_descriptions.get(col, col)}')\n",
    "    plt.xlabel(column_descriptions['BAD'])\n",
    "    plt.ylabel(column_descriptions.get(col, col))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'analytics/chapter2/boxplot_{col}_by_target.png')\n",
    "    plt.close()\n",
    "\n",
    "print(f\"Visualizations for {len(numeric_cols)} numeric features saved to 'analytics/chapter2/' directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue\">Categorical Features Analysis</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Features Analysis:\n",
      "\n",
      "REASON: Loan Purpose (DebtCon: debt consolidation, HomeImp: home improvement)\n",
      "Value counts:\n",
      "  DebtCon: 3928 (68.82%)\n",
      "  HomeImp: 1780 (31.18%)\n",
      "Missing values: 252 (4.23%)\n",
      "\n",
      "Default rates by category:\n",
      "  DebtCon: 18.97%\n",
      "  HomeImp: 22.25%\n",
      "\n",
      "JOB: Occupation Category\n",
      "Value counts:\n",
      "  Other: 2388 (42.03%)\n",
      "  ProfExe: 1276 (22.46%)\n",
      "  Office: 948 (16.69%)\n",
      "  Mgr: 767 (13.5%)\n",
      "  Self: 193 (3.4%)\n",
      "  Sales: 109 (1.92%)\n",
      "Missing values: 279 (4.68%)\n",
      "\n",
      "Default rates by category:\n",
      "  Mgr: 23.34%\n",
      "  Office: 13.19%\n",
      "  Other: 23.20%\n",
      "  ProfExe: 16.61%\n",
      "  Sales: 34.86%\n",
      "  Self: 30.05%\n",
      "Visualizations for categorical features saved to 'analytics/chapter2/' directory\n"
     ]
    }
   ],
   "source": [
    "# Analyze categorical features\n",
    "cat_cols = ['REASON', 'JOB']\n",
    "\n",
    "print(\"Categorical Features Analysis:\")\n",
    "for col in cat_cols:\n",
    "    print(f\"\\n{col}: {column_descriptions.get(col, col)}\")\n",
    "    \n",
    "    # Print value counts and percentages\n",
    "    val_counts = data[col].value_counts()\n",
    "    val_percentages = (val_counts / val_counts.sum() * 100).round(2)\n",
    "    \n",
    "    print(\"Value counts:\")\n",
    "    for category, count in val_counts.items():\n",
    "        print(f\"  {category}: {count} ({val_percentages[category]}%)\")\n",
    "    \n",
    "    # Print missing values\n",
    "    missing = data[col].isnull().sum()\n",
    "    missing_percent = (missing / len(data) * 100).round(2)\n",
    "    print(f\"Missing values: {missing} ({missing_percent}%)\")\n",
    "    \n",
    "    # Print default rates by category\n",
    "    default_rates = data.groupby(col)['BAD'].mean() * 100\n",
    "    print(\"\\nDefault rates by category:\")\n",
    "    for category, rate in default_rates.items():\n",
    "        print(f\"  {category}: {rate:.2f}%\")\n",
    "    \n",
    "    # Count plot of categorical variable\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Create plot\n",
    "    ax = sns.countplot(x=col, data=data, order=val_counts.index)\n",
    "    \n",
    "    # Rotate x-labels\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    plt.title(f'Distribution of {col}: {column_descriptions.get(col, col)}')\n",
    "    plt.xlabel(column_descriptions.get(col, col))\n",
    "    plt.ylabel('Count')\n",
    "    \n",
    "    # Add count labels\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(format(p.get_height(), '.0f'), \n",
    "                    (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha = 'center', va = 'center', \n",
    "                    xytext = (0, 10), \n",
    "                    textcoords = 'offset points')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'analytics/chapter2/categorical_{col}.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Distribution by target\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = sns.countplot(x=col, hue='BAD', data=data)\n",
    "    plt.title(f'Distribution of {col} by Target: {column_descriptions.get(col, col)}')\n",
    "    plt.xlabel(column_descriptions.get(col, col))\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend(title=column_descriptions['BAD'])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'analytics/chapter2/categorical_{col}_by_target.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Percentage of defaults by category\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    default_rate = data.groupby(col)['BAD'].mean() * 100\n",
    "    default_rate.sort_values(ascending=False).plot(kind='bar')\n",
    "    plt.title(f'Default Rate by {col}: {column_descriptions.get(col, col)}')\n",
    "    plt.xlabel(column_descriptions.get(col, col))\n",
    "    plt.ylabel('Default Rate (%)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'analytics/chapter2/default_rate_by_{col}.png')\n",
    "    plt.close()\n",
    "\n",
    "print(f\"Visualizations for categorical features saved to 'analytics/chapter2/' directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue\">Correlation Analysis</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 strongest feature correlations:\n",
      "VALUE & MORTDUE: 0.876\n",
      "DELINQ & BAD: 0.354\n",
      "VALUE & LOAN: 0.335\n",
      "CLNO & MORTDUE: 0.324\n",
      "DEROG & BAD: 0.276\n",
      "CLNO & VALUE: 0.269\n",
      "CLNO & CLAGE: 0.238\n",
      "MORTDUE & LOAN: 0.229\n",
      "DELINQ & DEROG: 0.212\n",
      "CLAGE & YOJ: 0.202\n",
      "Correlation matrix visualization saved to 'analytics/chapter2/correlation_matrix.png'\n"
     ]
    }
   ],
   "source": [
    "# Correlation analysis for numeric columns only\n",
    "numeric_data = data.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr = numeric_data.corr()\n",
    "\n",
    "# Print strongest correlations\n",
    "print(\"Top 10 strongest feature correlations:\")\n",
    "corr_pairs = []\n",
    "for i in range(len(corr.columns)):\n",
    "    for j in range(i):\n",
    "        if i != j:  # Avoid diagonal\n",
    "            corr_pairs.append((corr.columns[i], corr.columns[j], corr.iloc[i, j]))\n",
    "\n",
    "# Sort by absolute correlation and print top 10\n",
    "corr_pairs.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "for var1, var2, corr_val in corr_pairs[:10]:\n",
    "    print(f\"{var1} & {var2}: {corr_val:.3f}\")\n",
    "\n",
    "# Create correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "sns.heatmap(corr, mask=mask, annot=True, fmt='.2f', cmap='coolwarm', square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('analytics/chapter2/correlation_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Correlation matrix visualization saved to 'analytics/chapter2/correlation_matrix.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3 (General Model Development)\n",
    "\n",
    "The data is split 80/20 for training/testing with stratification to maintain class distribution. </br></br>\n",
    "Missing values are handled in two ways:</br>\n",
    "* Numeric features: Assigned median values to reduce outlier impact</br>\n",
    "* Categorical features: Assigned the most frequent value </br>\n",
    "\n",
    "Numeric features are standardised (mean = 0, standard deviation = 1) to improve model performance.</br>\n",
    "Categorical features are one-hot encoded to convert them to numeric format.\n",
    "\n",
    "<b>3 different algorithms</b> were chosen to represent different modeling approaches:</br>\n",
    "* Logistic Regression: Linear model with L2 regularization, max_iter=1000</br>\n",
    "* Random Forest: Ensemble of decision trees with default parameters</br>\n",
    "* XGBoost: Gradient boosting implementation with default parameters</br>\n",
    "\n",
    "Random state 42 is used consistently to ensure reproducibility</br>\n",
    "No explicit hyperparameter tuning is implemented in the initial modeling phase</br>\n",
    "\n",
    "<span style=\"color:red\">Future Works for Chapter 3:</span>\n",
    "* Implement cross-validation for more robust performance estimates</br>\n",
    "* Conduct hyperparameter tuning using GridSearchCV or Bayesian optimization</br>\n",
    "* Try additional models such as neural networks or SVM</br>\n",
    "* Implement stacking or voting ensembles to combine model strengths</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue\">Data Preparation</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for modeling...\n",
      "Training set shape: (4768, 12), (4768,)\n",
      "Testing set shape: (1192, 12), (1192,)\n",
      "Class distribution in training set: {0: 3817, 1: 951}\n",
      "Class distribution in testing set: {0: 954, 1: 238}\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing data for modeling...\")\n",
    "\n",
    "# Fill missing values for analysis\n",
    "data_filled = data.copy()\n",
    "\n",
    "# Fill missing numeric values with median\n",
    "numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "numeric_cols = [col for col in numeric_cols if col != 'BAD']\n",
    "for col in numeric_cols:\n",
    "    data_filled[col] = data_filled[col].fillna(data_filled[col].median())\n",
    "\n",
    "# Fill missing categorical values with mode\n",
    "cat_cols = ['REASON', 'JOB']\n",
    "for col in cat_cols:\n",
    "    data_filled[col] = data_filled[col].fillna(data_filled[col].mode()[0])\n",
    "\n",
    "X = data_filled.drop('BAD', axis=1)\n",
    "y = data_filled['BAD']\n",
    "\n",
    "# Define features\n",
    "categorical_features = ['REASON', 'JOB']\n",
    "numerical_features = [col for col in X.columns if col not in categorical_features]\n",
    "\n",
    "# Define preprocessing for numerical and categorical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}, {y_test.shape}\")\n",
    "print(f\"Class distribution in training set: {dict(y_train.value_counts())}\")\n",
    "print(f\"Class distribution in testing set: {dict(y_test.value_counts())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue\">Initial Feature Importance Analysis (using Random Forest)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing feature importance...\n",
      "Feature importances from Random Forest:\n",
      "1. DEBTINC: 0.2328\n",
      "2. CLAGE: 0.1057\n",
      "3. DELINQ: 0.0984\n",
      "4. LOAN: 0.0926\n",
      "5. VALUE: 0.0866\n",
      "6. MORTDUE: 0.0815\n",
      "7. CLNO: 0.0780\n",
      "8. YOJ: 0.0604\n",
      "9. DEROG: 0.0538\n",
      "10. NINQ: 0.0441\n",
      "11. JOB_Other: 0.0110\n",
      "12. JOB_Office: 0.0105\n",
      "13. REASON_HomeImp: 0.0096\n",
      "14. REASON_DebtCon: 0.0092\n",
      "15. JOB_ProfExe: 0.0085\n",
      "16. JOB_Mgr: 0.0065\n",
      "17. JOB_Sales: 0.0062\n",
      "18. JOB_Self: 0.0046\n",
      "Feature importance visualization saved to 'analytics/chapter3/rf_feature_importances.png'\n"
     ]
    }
   ],
   "source": [
    "print(\"Analyzing feature importance...\")\n",
    "\n",
    "rf_clf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Get feature names after one-hot encoding\n",
    "feature_names = numerical_features.copy()\n",
    "categorical_features_encoded = []\n",
    "for name, transformer in rf_clf.named_steps['preprocessor'].named_transformers_.items():\n",
    "    if name == 'cat':\n",
    "        for feature, categories in zip(categorical_features, transformer.named_steps['onehot'].categories_):\n",
    "            for category in categories:\n",
    "                categorical_features_encoded.append(f\"{feature}_{category}\")\n",
    "        \n",
    "feature_names_encoded = feature_names + categorical_features_encoded\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf_clf.named_steps['classifier'].feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print feature importances\n",
    "print(\"Feature importances from Random Forest:\")\n",
    "for i in range(min(20, len(indices))):\n",
    "    if i < len(feature_names_encoded):\n",
    "        print(f\"{i+1}. {feature_names_encoded[indices[i]]}: {importances[indices[i]]:.4f}\")\n",
    "    else:\n",
    "        print(f\"{i+1}. Feature {indices[i]}: {importances[indices[i]]:.4f}\")\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(min(20, len(indices))), importances[indices][:20], align='center')\n",
    "plt.yticks(range(min(20, len(indices))), [feature_names_encoded[i] if i < len(feature_names_encoded) else f\"Feature {i}\" for i in indices[:20]])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.tight_layout()\n",
    "plt.savefig('analytics/chapter3/rf_feature_importances.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Feature importance visualization saved to 'analytics/chapter3/rf_feature_importances.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue\">Model Development (3 Models)</span>\n",
    "\n",
    "At the end of this section there is a comparison of\n",
    "- LR (Logistic Regression)\n",
    "- RF (Random Forest)\n",
    "- XGB (XGBoost)</br>\n",
    "\n",
    "models using their ROC curves. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:lightblue\">Logistic Regression</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression model...\n",
      "\n",
      "Logistic Regression Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91       954\n",
      "           1       0.71      0.34      0.46       238\n",
      "\n",
      "    accuracy                           0.84      1192\n",
      "   macro avg       0.78      0.65      0.69      1192\n",
      "weighted avg       0.83      0.84      0.82      1192\n",
      "\n",
      "Logistic Regression results saved to 'analytics/chapter3/' directory\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Logistic Regression model...\")\n",
    "\n",
    "log_reg = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42, max_iter=1000))\n",
    "])\n",
    "\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_lr = log_reg.predict(X_test)\n",
    "y_prob_lr = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nLogistic Regression Results:\")\n",
    "lr_report = classification_report(y_test, y_pred_lr)\n",
    "print(lr_report)\n",
    "\n",
    "# Save classification report\n",
    "with open('analytics/chapter3/lr_classification_report.txt', 'w') as f:\n",
    "    f.write(lr_report)\n",
    "\n",
    "# Save confusion matrix\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Logistic Regression Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig('analytics/chapter3/lr_confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Logistic Regression results saved to 'analytics/chapter3/' directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:lightblue\">Random Forest</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest model...\n",
      "\n",
      "Random Forest Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94       954\n",
      "           1       0.87      0.63      0.73       238\n",
      "\n",
      "    accuracy                           0.91      1192\n",
      "   macro avg       0.89      0.81      0.84      1192\n",
      "weighted avg       0.91      0.91      0.90      1192\n",
      "\n",
      "Random Forest results saved to 'analytics/chapter3/' directory\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Random Forest model...\")\n",
    "\n",
    "random_forest = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred_rf = random_forest.predict(X_test)\n",
    "y_prob_rf = random_forest.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nRandom Forest Results:\")\n",
    "rf_report = classification_report(y_test, y_pred_rf)\n",
    "print(rf_report)\n",
    "\n",
    "# Save classification report\n",
    "with open('analytics/chapter3/rf_classification_report.txt', 'w') as f:\n",
    "    f.write(rf_report)\n",
    "\n",
    "# Save confusion matrix\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Random Forest Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig('analytics/chapter3/rf_confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Random Forest results saved to 'analytics/chapter3/' directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:lightblue\">XGBoost</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost model...\n",
      "\n",
      "XGBoost Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94       954\n",
      "           1       0.84      0.66      0.74       238\n",
      "\n",
      "    accuracy                           0.91      1192\n",
      "   macro avg       0.88      0.81      0.84      1192\n",
      "weighted avg       0.90      0.91      0.90      1192\n",
      "\n",
      "XGBoost results saved to 'analytics/chapter3/' directory\n"
     ]
    }
   ],
   "source": [
    "print(\"Training XGBoost model...\")\n",
    "\n",
    "xgb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', XGBClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "xgb_pipeline.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_pipeline.predict(X_test)\n",
    "y_prob_xgb = xgb_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nXGBoost Results:\")\n",
    "xgb_report = classification_report(y_test, y_pred_xgb)\n",
    "print(xgb_report)\n",
    "\n",
    "# Save classification report\n",
    "with open('analytics/chapter3/xgb_classification_report.txt', 'w') as f:\n",
    "    f.write(xgb_report)\n",
    "\n",
    "# Save confusion matrix\n",
    "cm_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_xgb, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('XGBoost Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig('analytics/chapter3/xgb_confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"XGBoost results saved to 'analytics/chapter3/' directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:lightblue\">Model Comparison - ROC Curves</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing models using ROC curves...\n",
      "ROC Curve comparison saved to 'analytics/chapter3/roc_comparison.png'\n",
      "\n",
      "AUC Scores:\n",
      "Logistic Regression: 0.7643\n",
      "Random Forest: 0.9644\n",
      "XGBoost: 0.9507\n"
     ]
    }
   ],
   "source": [
    "# ROC Curve Comparison\n",
    "print(\"Comparing models using ROC curves...\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "# Logistic Regression\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_prob_lr)\n",
    "auc_lr = roc_auc_score(y_test, y_prob_lr)\n",
    "plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {auc_lr:.3f})')\n",
    "\n",
    "# Random Forest\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_prob_rf)\n",
    "auc_rf = roc_auc_score(y_test, y_prob_rf)\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {auc_rf:.3f})')\n",
    "\n",
    "# XGBoost\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, y_prob_xgb)\n",
    "auc_xgb = roc_auc_score(y_test, y_prob_xgb)\n",
    "plt.plot(fpr_xgb, tpr_xgb, label=f'XGBoost (AUC = {auc_xgb:.3f})')\n",
    "\n",
    "# Add diagonal line (random classifier)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Comparison')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('analytics/chapter3/roc_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"ROC Curve comparison saved to 'analytics/chapter3/roc_comparison.png'\")\n",
    "print(f\"\\nAUC Scores:\")\n",
    "print(f\"Logistic Regression: {auc_lr:.4f}\")\n",
    "print(f\"Random Forest: {auc_rf:.4f}\")\n",
    "print(f\"XGBoost: {auc_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:lightblue\">Combined (3 Models) Feature Importance Comparison</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 features for Logistic Regression:\n",
      "1. DEBTINC (0.5093)\n",
      "2. CLAGE (0.4936)\n",
      "3. DELINQ (0.8593)\n",
      "4. LOAN (0.2502)\n",
      "5. VALUE (0.1521)\n",
      "\n",
      "Top 5 features for Random Forest:\n",
      "1. DEBTINC (0.2328)\n",
      "2. CLAGE (0.1057)\n",
      "3. DELINQ (0.0984)\n",
      "4. LOAN (0.0926)\n",
      "5. VALUE (0.0866)\n",
      "\n",
      "Top 5 features for XGBoost:\n",
      "1. DEBTINC (0.2366)\n",
      "2. CLAGE (0.0441)\n",
      "3. DELINQ (0.1703)\n",
      "4. LOAN (0.0330)\n",
      "5. VALUE (0.0299)\n",
      "\n",
      "Feature importance comparison across models:\n",
      "          Feature Important in LR Important in RF Important in XGB\n",
      "0          DELINQ               ✓               ✓                ✓\n",
      "1       JOB_Sales               ✓               ✗                ✓\n",
      "2           DEROG               ✓               ✓                ✓\n",
      "3      JOB_Office               ✓               ✗                ✓\n",
      "4           CLAGE               ✓               ✓                ✓\n",
      "5            LOAN               ✗               ✓                ✓\n",
      "6           VALUE               ✗               ✓                ✗\n",
      "7         DEBTINC               ✓               ✓                ✓\n",
      "8  REASON_DebtCon               ✓               ✗                ✗\n",
      "Feature importance comparison visualizations saved to 'analytics/chapter3/3models_feature_importances/' directory\n"
     ]
    }
   ],
   "source": [
    "# Create a directory for feature importance plots\n",
    "if not os.path.exists('analytics/chapter3/3models_feature_importances'):\n",
    "    os.makedirs('analytics/chapter3/3models_feature_importances')\n",
    "\n",
    "# Function to plot feature importance\n",
    "def plot_feature_importance(importances, feature_names, model_name, top_n=15):\n",
    "    # Sort features by importance\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    # Select top N features\n",
    "    indices = indices[:top_n]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title(f'Top {top_n} Feature Importance - {model_name}')\n",
    "    plt.barh(range(len(indices)), importances[indices], align='center')\n",
    "    plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'analytics/chapter3/3models_feature_importances/{model_name.lower().replace(\" \", \"_\")}_importance.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Also save the data to CSV\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importances\n",
    "    })\n",
    "    importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "    importance_df.to_csv(f'analytics/chapter3/3models_feature_importances/{model_name.lower().replace(\" \", \"_\")}_importance.csv', index=False)\n",
    "    \n",
    "    return indices\n",
    "\n",
    "# Get feature names after preprocessing (for proper feature importance)\n",
    "feature_names = numerical_features.copy()\n",
    "categorical_features_encoded = []\n",
    "for name, transformer in rf_clf.named_steps['preprocessor'].named_transformers_.items():\n",
    "    if name == 'cat':\n",
    "        for feature, categories in zip(categorical_features, transformer.named_steps['onehot'].categories_):\n",
    "            for category in categories:\n",
    "                categorical_features_encoded.append(f\"{feature}_{category}\")\n",
    "        \n",
    "feature_names_encoded = feature_names + categorical_features_encoded\n",
    "\n",
    "# 1. Logistic Regression Feature Importance\n",
    "# Access coefficients from the classifier inside the pipeline\n",
    "lr_importances = np.abs(log_reg.named_steps['classifier'].coef_[0])\n",
    "lr_indices = plot_feature_importance(lr_importances, feature_names_encoded, 'Logistic Regression')\n",
    "print(\"Top 5 features for Logistic Regression:\")\n",
    "print(\"\\n\".join([f\"{i+1}. {feature_names_encoded[indices[i]]} ({lr_importances[indices[i]]:.4f})\" for i in range(5)]))\n",
    "\n",
    "# 2. Random Forest Feature Importance\n",
    "rf_importances = rf_clf.named_steps['classifier'].feature_importances_\n",
    "rf_indices = plot_feature_importance(rf_importances, feature_names_encoded, 'Random Forest')\n",
    "print(\"\\nTop 5 features for Random Forest:\")\n",
    "print(\"\\n\".join([f\"{i+1}. {feature_names_encoded[indices[i]]} ({rf_importances[indices[i]]:.4f})\" for i in range(5)]))\n",
    "\n",
    "# 3. XGBoost Feature Importance\n",
    "xgb_importances = xgb_pipeline.named_steps['classifier'].feature_importances_\n",
    "xgb_indices = plot_feature_importance(xgb_importances, feature_names_encoded, 'XGBoost')\n",
    "print(\"\\nTop 5 features for XGBoost:\")\n",
    "print(\"\\n\".join([f\"{i+1}. {feature_names_encoded[indices[i]]} ({xgb_importances[indices[i]]:.4f})\" for i in range(5)]))\n",
    "\n",
    "# Create comparison visualization for top features across models\n",
    "top_features = set()\n",
    "for i in range(5):\n",
    "    if i < len(lr_indices): top_features.add(feature_names_encoded[lr_indices[i]])\n",
    "    if i < len(rf_indices): top_features.add(feature_names_encoded[rf_indices[i]])\n",
    "    if i < len(xgb_indices): top_features.add(feature_names_encoded[xgb_indices[i]])\n",
    "\n",
    "# Create a comparison table\n",
    "comparison_data = []\n",
    "for feature in top_features:\n",
    "    idx = feature_names_encoded.index(feature)\n",
    "    lr_rank = idx in lr_indices[:10]\n",
    "    rf_rank = idx in rf_indices[:10]\n",
    "    xgb_rank = idx in xgb_indices[:10]\n",
    "    \n",
    "    comparison_data.append({\n",
    "        'Feature': feature,\n",
    "        'Important in LR': '✓' if lr_rank else '✗',\n",
    "        'Important in RF': '✓' if rf_rank else '✗',\n",
    "        'Important in XGB': '✓' if xgb_rank else '✗'\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df.to_csv('analytics/chapter3/3models_feature_importances/model_comparison.csv', index=False)\n",
    "print(\"\\nFeature importance comparison across models:\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Create a combined bar chart visualization\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.title('Top Feature Importance Comparison Across Models')\n",
    "\n",
    "# Get top features across all models (limited to 8 for readability)\n",
    "top_features_list = list(top_features)[:8] \n",
    "\n",
    "x = np.arange(len(top_features_list))\n",
    "width = 0.25\n",
    "\n",
    "# Prepare data for plotting\n",
    "lr_values = []\n",
    "rf_values = []\n",
    "xgb_values = []\n",
    "\n",
    "for feature in top_features_list:\n",
    "    idx = feature_names_encoded.index(feature)\n",
    "    lr_values.append(lr_importances[idx] / np.sum(lr_importances))  # Normalize\n",
    "    rf_values.append(rf_importances[idx] / np.sum(rf_importances))  # Normalize\n",
    "    xgb_values.append(xgb_importances[idx] / np.sum(xgb_importances))  # Normalize\n",
    "\n",
    "# Plot bars\n",
    "plt.bar(x - width, lr_values, width, label='Logistic Regression')\n",
    "plt.bar(x, rf_values, width, label='Random Forest')\n",
    "plt.bar(x + width, xgb_values, width, label='XGBoost')\n",
    "\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Normalized Importance')\n",
    "plt.xticks(x, top_features_list, rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('analytics/chapter3/3models_feature_importances/combined_importance.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Feature importance comparison visualizations saved to 'analytics/chapter3/3models_feature_importances/' directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4 (Model Development for Objectives 1 & 2)\n",
    "\n",
    "Assumptions and Details:</br>\n",
    "Threshold optimization is performed by finding the point on the ROC curve that satisfies each objective.</br>\n",
    "Default threshold of 0.5 is not assumed to be optimal.</br>\n",
    "Performance metrics focus on recall for the relevant class for each objective.</br>\n",
    "Assumes false positives and false negatives have different business costs.</br>\n",
    "\n",
    "<span style=\"color:red\">Future Works for Chapter 4:</span>\n",
    "* Implement cost-sensitive learning to directly optimize for business objectives\n",
    "* Perform sensitivity analysis to understand how robust thresholds are to changes in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue\">Objective 1</span>\n",
    "\n",
    "Objective 1 is defined as, accepting the maxumim number of good customers if at least 85% of bad customers are correctly identified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression:\n",
      "Threshold: 0.089\n",
      "Percentage of bad customers correctly identified: 84.87%\n",
      "Percentage of good customers accepted: 44.97%\n",
      "Overall accuracy: 52.94%\n",
      "Confusion Matrix: TN=429, FP=525, FN=36, TP=202\n",
      "\n",
      "Random Forest:\n",
      "Threshold: 0.330\n",
      "Percentage of bad customers correctly identified: 84.87%\n",
      "Percentage of good customers accepted: 92.87%\n",
      "Overall accuracy: 91.28%\n",
      "Confusion Matrix: TN=886, FP=68, FN=36, TP=202\n",
      "\n",
      "XGBoost:\n",
      "Threshold: 0.110\n",
      "Percentage of bad customers correctly identified: 85.29%\n",
      "Percentage of good customers accepted: 91.93%\n",
      "Overall accuracy: 90.60%\n",
      "Confusion Matrix: TN=877, FP=77, FN=35, TP=203\n",
      "Objective 1 results saved to 'analytics/chapter4/' directory\n"
     ]
    }
   ],
   "source": [
    "def find_threshold_for_recall(y_true, y_prob, target_recall=0.85):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
    "    recall = tpr  # TPR is the same as recall\n",
    "    idx = np.argmin(np.abs(recall - target_recall))\n",
    "    return thresholds[idx], tpr[idx], 1-fpr[idx]  # threshold, actual recall, specificity\n",
    "\n",
    "# Find thresholds for 85% recall on bad customers\n",
    "threshold_lr_obj1, recall_lr_obj1, spec_lr_obj1 = find_threshold_for_recall(y_test, y_prob_lr, 0.85)\n",
    "threshold_rf_obj1, recall_rf_obj1, spec_rf_obj1 = find_threshold_for_recall(y_test, y_prob_rf, 0.85)\n",
    "threshold_xgb_obj1, recall_xgb_obj1, spec_xgb_obj1 = find_threshold_for_recall(y_test, y_prob_xgb, 0.85)\n",
    "\n",
    "# Evaluate models with these thresholds\n",
    "def evaluate_with_threshold(y_true, y_prob, threshold):\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    \n",
    "    # For BAD=1 class\n",
    "    recall_bad = report['1']['recall']  # Percentage of bad customers correctly identified\n",
    "    precision_bad = report['1']['precision']  # Precision for bad customers\n",
    "    \n",
    "    # For BAD=0 class\n",
    "    recall_good = report['0']['recall']  # Percentage of good customers accepted\n",
    "    \n",
    "    # Overall accuracy\n",
    "    accuracy = report['accuracy']\n",
    "    \n",
    "    # Confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    \n",
    "    return {\n",
    "        'threshold': threshold,\n",
    "        'accuracy': accuracy,\n",
    "        'recall_bad': recall_bad,  # sensitivity for bad class\n",
    "        'precision_bad': precision_bad,\n",
    "        'recall_good': recall_good,  # specificity for bad class\n",
    "        'tn': tn,  # true negative (correctly identified good customers)\n",
    "        'fp': fp,  # false positive (good customers misclassified as bad)\n",
    "        'fn': fn,  # false negative (bad customers misclassified as good)\n",
    "        'tp': tp   # true positive (correctly identified bad customers)\n",
    "    }\n",
    "\n",
    "print(\"\\nLogistic Regression:\")\n",
    "lr_obj1_results = evaluate_with_threshold(y_test, y_prob_lr, threshold_lr_obj1)\n",
    "print(f\"Threshold: {lr_obj1_results['threshold']:.3f}\")\n",
    "print(f\"Percentage of bad customers correctly identified: {lr_obj1_results['recall_bad']:.2%}\")\n",
    "print(f\"Percentage of good customers accepted: {lr_obj1_results['recall_good']:.2%}\")\n",
    "print(f\"Overall accuracy: {lr_obj1_results['accuracy']:.2%}\")\n",
    "print(f\"Confusion Matrix: TN={lr_obj1_results['tn']}, FP={lr_obj1_results['fp']}, FN={lr_obj1_results['fn']}, TP={lr_obj1_results['tp']}\")\n",
    "\n",
    "print(\"\\nRandom Forest:\")\n",
    "rf_obj1_results = evaluate_with_threshold(y_test, y_prob_rf, threshold_rf_obj1)\n",
    "print(f\"Threshold: {rf_obj1_results['threshold']:.3f}\")\n",
    "print(f\"Percentage of bad customers correctly identified: {rf_obj1_results['recall_bad']:.2%}\")\n",
    "print(f\"Percentage of good customers accepted: {rf_obj1_results['recall_good']:.2%}\")\n",
    "print(f\"Overall accuracy: {rf_obj1_results['accuracy']:.2%}\")\n",
    "print(f\"Confusion Matrix: TN={rf_obj1_results['tn']}, FP={rf_obj1_results['fp']}, FN={rf_obj1_results['fn']}, TP={rf_obj1_results['tp']}\")\n",
    "\n",
    "print(\"\\nXGBoost:\")\n",
    "xgb_obj1_results = evaluate_with_threshold(y_test, y_prob_xgb, threshold_xgb_obj1)\n",
    "print(f\"Threshold: {xgb_obj1_results['threshold']:.3f}\")\n",
    "print(f\"Percentage of bad customers correctly identified: {xgb_obj1_results['recall_bad']:.2%}\")\n",
    "print(f\"Percentage of good customers accepted: {xgb_obj1_results['recall_good']:.2%}\")\n",
    "print(f\"Overall accuracy: {xgb_obj1_results['accuracy']:.2%}\")\n",
    "print(f\"Confusion Matrix: TN={xgb_obj1_results['tn']}, FP={xgb_obj1_results['fp']}, FN={xgb_obj1_results['fn']}, TP={xgb_obj1_results['tp']}\")\n",
    "\n",
    "# Create a better formatted table for Objective 1\n",
    "obj1_data = {\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'XGBoost'],\n",
    "    'Threshold': [lr_obj1_results['threshold'], rf_obj1_results['threshold'], xgb_obj1_results['threshold']],\n",
    "    'Bad Customers Identified (%)': [lr_obj1_results['recall_bad']*100, rf_obj1_results['recall_bad']*100, xgb_obj1_results['recall_bad']*100],\n",
    "    'Good Customers Accepted (%)': [lr_obj1_results['recall_good']*100, rf_obj1_results['recall_good']*100, xgb_obj1_results['recall_good']*100],\n",
    "    'Accuracy (%)': [lr_obj1_results['accuracy']*100, rf_obj1_results['accuracy']*100, xgb_obj1_results['accuracy']*100]\n",
    "}\n",
    "\n",
    "obj1_df = pd.DataFrame(obj1_data)\n",
    "\n",
    "# Save results to CSV\n",
    "obj1_df.to_csv('analytics/chapter4/objective1_results.csv', index=False)\n",
    "\n",
    "# Create a more visually appealing table\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "ax.axis('off')\n",
    "ax.axis('tight')\n",
    "\n",
    "# Create table with better formatting\n",
    "table = ax.table(\n",
    "    cellText=obj1_df.round(2).values,\n",
    "    colLabels=obj1_df.columns,\n",
    "    cellLoc='center',\n",
    "    loc='center',\n",
    "    colColours=['#f2f2f2']*len(obj1_df.columns),\n",
    "    cellColours=[['#f9f9f9']*len(obj1_df.columns)]*len(obj1_df)\n",
    ")\n",
    "\n",
    "# Style the table\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "table.scale(1, 1.5)  # Adjust row height\n",
    "\n",
    "# Add a title with proper padding\n",
    "plt.title('Objective 1: Accept max good customers if at least 85% of bad customers are identified', \n",
    "          fontsize=14, pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('analytics/chapter4/objective1_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"Objective 1 results saved to 'analytics/chapter4/' directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue\">Objective 2</span>\n",
    "\n",
    "Objective 2 is defined as, accepting at least 70% of good customers while rejecting as many bad customers as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression:\n",
      "Threshold: 0.163\n",
      "Percentage of bad customers correctly identified: 65.13%\n",
      "Percentage of good customers accepted: 69.60%\n",
      "Overall accuracy: 68.71%\n",
      "Confusion Matrix: TN=664, FP=290, FN=83, TP=155\n",
      "\n",
      "Random Forest:\n",
      "Threshold: 0.070\n",
      "Percentage of bad customers correctly identified: 98.32%\n",
      "Percentage of good customers accepted: 70.13%\n",
      "Overall accuracy: 75.76%\n",
      "Confusion Matrix: TN=669, FP=285, FN=4, TP=234\n",
      "\n",
      "XGBoost:\n",
      "Threshold: 0.014\n",
      "Percentage of bad customers correctly identified: 96.64%\n",
      "Percentage of good customers accepted: 71.28%\n",
      "Overall accuracy: 76.34%\n",
      "Confusion Matrix: TN=680, FP=274, FN=8, TP=230\n",
      "Objective 2 results saved to 'analytics/chapter4/' directory\n"
     ]
    }
   ],
   "source": [
    "def find_threshold_for_specificity(y_true, y_prob, target_specificity=0.70):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
    "    specificity = 1 - fpr\n",
    "    idx = np.argmin(np.abs(specificity - target_specificity))\n",
    "    return thresholds[idx], tpr[idx], specificity[idx]  # threshold, recall, actual specificity\n",
    "\n",
    "# Find thresholds for 70% specificity on good customers\n",
    "threshold_lr_obj2, recall_lr_obj2, spec_lr_obj2 = find_threshold_for_specificity(y_test, y_prob_lr, 0.70)\n",
    "threshold_rf_obj2, recall_rf_obj2, spec_rf_obj2 = find_threshold_for_specificity(y_test, y_prob_rf, 0.70)\n",
    "threshold_xgb_obj2, recall_xgb_obj2, spec_xgb_obj2 = find_threshold_for_specificity(y_test, y_prob_xgb, 0.70)\n",
    "\n",
    "print(\"\\nLogistic Regression:\")\n",
    "lr_obj2_results = evaluate_with_threshold(y_test, y_prob_lr, threshold_lr_obj2)\n",
    "print(f\"Threshold: {lr_obj2_results['threshold']:.3f}\")\n",
    "print(f\"Percentage of bad customers correctly identified: {lr_obj2_results['recall_bad']:.2%}\")\n",
    "print(f\"Percentage of good customers accepted: {lr_obj2_results['recall_good']:.2%}\")\n",
    "print(f\"Overall accuracy: {lr_obj2_results['accuracy']:.2%}\")\n",
    "print(f\"Confusion Matrix: TN={lr_obj2_results['tn']}, FP={lr_obj2_results['fp']}, FN={lr_obj2_results['fn']}, TP={lr_obj2_results['tp']}\")\n",
    "\n",
    "print(\"\\nRandom Forest:\")\n",
    "rf_obj2_results = evaluate_with_threshold(y_test, y_prob_rf, threshold_rf_obj2)\n",
    "print(f\"Threshold: {rf_obj2_results['threshold']:.3f}\")\n",
    "print(f\"Percentage of bad customers correctly identified: {rf_obj2_results['recall_bad']:.2%}\")\n",
    "print(f\"Percentage of good customers accepted: {rf_obj2_results['recall_good']:.2%}\")\n",
    "print(f\"Overall accuracy: {rf_obj2_results['accuracy']:.2%}\")\n",
    "print(f\"Confusion Matrix: TN={rf_obj2_results['tn']}, FP={rf_obj2_results['fp']}, FN={rf_obj2_results['fn']}, TP={rf_obj2_results['tp']}\")\n",
    "\n",
    "print(\"\\nXGBoost:\")\n",
    "xgb_obj2_results = evaluate_with_threshold(y_test, y_prob_xgb, threshold_xgb_obj2)\n",
    "print(f\"Threshold: {xgb_obj2_results['threshold']:.3f}\")\n",
    "print(f\"Percentage of bad customers correctly identified: {xgb_obj2_results['recall_bad']:.2%}\")\n",
    "print(f\"Percentage of good customers accepted: {xgb_obj2_results['recall_good']:.2%}\")\n",
    "print(f\"Overall accuracy: {xgb_obj2_results['accuracy']:.2%}\")\n",
    "print(f\"Confusion Matrix: TN={xgb_obj2_results['tn']}, FP={xgb_obj2_results['fp']}, FN={xgb_obj2_results['fn']}, TP={xgb_obj2_results['tp']}\")\n",
    "\n",
    "# Create a better formatted table for Objective 2\n",
    "obj2_data = {\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'XGBoost'],\n",
    "    'Threshold': [lr_obj2_results['threshold'], rf_obj2_results['threshold'], xgb_obj2_results['threshold']],\n",
    "    'Bad Customers Identified (%)': [lr_obj2_results['recall_bad']*100, rf_obj2_results['recall_bad']*100, xgb_obj2_results['recall_bad']*100],\n",
    "    'Good Customers Accepted (%)': [lr_obj2_results['recall_good']*100, rf_obj2_results['recall_good']*100, xgb_obj2_results['recall_good']*100],\n",
    "    'Accuracy (%)': [lr_obj2_results['accuracy']*100, rf_obj2_results['accuracy']*100, xgb_obj2_results['accuracy']*100]\n",
    "}\n",
    "\n",
    "obj2_df = pd.DataFrame(obj2_data)\n",
    "\n",
    "# Save results to CSV\n",
    "obj2_df.to_csv('analytics/chapter4/objective2_results.csv', index=False)\n",
    "\n",
    "# Create a more visually appealing table\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "ax.axis('off')\n",
    "ax.axis('tight')\n",
    "\n",
    "# Create table with better formatting\n",
    "table = ax.table(\n",
    "    cellText=obj2_df.round(2).values,\n",
    "    colLabels=obj2_df.columns,\n",
    "    cellLoc='center',\n",
    "    loc='center',\n",
    "    colColours=['#f2f2f2']*len(obj2_df.columns),\n",
    "    cellColours=[['#f9f9f9']*len(obj2_df.columns)]*len(obj2_df)\n",
    ")\n",
    "\n",
    "# Style the table\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "table.scale(1, 1.5)  # Adjust row height\n",
    "\n",
    "# Add a title with proper padding\n",
    "plt.title('Objective 2: Accept at least 70% of good customers with max bad customer rejection', \n",
    "          fontsize=14, pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('analytics/chapter4/objective2_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"Objective 2 results saved to 'analytics/chapter4/' directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5 (Model Comparison)\n",
    "\n",
    "Assumptions and Details:</br>\n",
    "Profit from a good customer paying back: <b>$1,500</b></br>\n",
    "Loss from a bad customer defaulting: <b>$10,000</b></br>\n",
    "These values represent average profit/loss per customer.</br>\n",
    "Analysis scales results to show impact per <b>1,000 applications.</b></br>\n",
    "Net impact is calculated by combining the financial effects of both correct and incorrect decisions.</br>\n",
    "\n",
    "<span style=\"color:red\">Future Works for Chapter 5:</span>\n",
    "* Incorporate varying loan amounts to create more personalized profit/loss estimates\n",
    "* Create what-if analysis tools to evaluate different scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue\">Model Performance Comparison (Objectives 1 & 2)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model performance comparison visualizations...\n",
      "Model performance visualizations saved to 'analytics/chapter5/' directory\n"
     ]
    }
   ],
   "source": [
    "# Bar chart of model performance by objective\n",
    "print(\"Creating model performance comparison visualizations...\")\n",
    "\n",
    "# Objective 1 chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "models = ['Logistic Regression', 'Random Forest', 'XGBoost']\n",
    "bad_identified_obj1 = [lr_obj1_results['recall_bad']*100, rf_obj1_results['recall_bad']*100, xgb_obj1_results['recall_bad']*100]\n",
    "good_accepted_obj1 = [lr_obj1_results['recall_good']*100, rf_obj1_results['recall_good']*100, xgb_obj1_results['recall_good']*100]\n",
    "\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, bad_identified_obj1, width, label='Bad Customers Identified (%)')\n",
    "plt.bar(x + width/2, good_accepted_obj1, width, label='Good Customers Accepted (%)')\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Percentage (%)')\n",
    "plt.title('Objective 1: Model Performance Comparison')\n",
    "plt.xticks(x, models)\n",
    "plt.ylim(0, 100)\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig('analytics/chapter5/objective1_performance.png')\n",
    "plt.close()\n",
    "\n",
    "# Objective 2 chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "bad_identified_obj2 = [lr_obj2_results['recall_bad']*100, rf_obj2_results['recall_bad']*100, xgb_obj2_results['recall_bad']*100]\n",
    "good_accepted_obj2 = [lr_obj2_results['recall_good']*100, rf_obj2_results['recall_good']*100, xgb_obj2_results['recall_good']*100]\n",
    "\n",
    "plt.bar(x - width/2, bad_identified_obj2, width, label='Bad Customers Identified (%)')\n",
    "plt.bar(x + width/2, good_accepted_obj2, width, label='Good Customers Accepted (%)')\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Percentage (%)')\n",
    "plt.title('Objective 2: Model Performance Comparison')\n",
    "plt.xticks(x, models)\n",
    "plt.ylim(0, 100)\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig('analytics/chapter5/objective2_performance.png')\n",
    "plt.close()\n",
    "\n",
    "# Combined chart showing both objectives\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# Objective 1\n",
    "ax1.bar(x - width/2, bad_identified_obj1, width, label='Bad Customers Identified (%)')\n",
    "ax1.bar(x + width/2, good_accepted_obj1, width, label='Good Customers Accepted (%)')\n",
    "ax1.set_xlabel('Models')\n",
    "ax1.set_ylabel('Percentage (%)')\n",
    "ax1.set_title('Objective 1: Accept max good customers if 85% of bad customers are identified')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(models)\n",
    "ax1.set_ylim(0, 100)\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Objective 2\n",
    "ax2.bar(x - width/2, bad_identified_obj2, width, label='Bad Customers Identified (%)')\n",
    "ax2.bar(x + width/2, good_accepted_obj2, width, label='Good Customers Accepted (%)')\n",
    "ax2.set_xlabel('Models')\n",
    "ax2.set_ylabel('Percentage (%)')\n",
    "ax2.set_title('Objective 2: Accept at least 70% of good customers with max bad rejection')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(models)\n",
    "ax2.set_ylim(0, 100)\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('analytics/chapter5/model_performance_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Model performance visualizations saved to 'analytics/chapter5/' directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue\">Cost-Benefit Analysis</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Objective 1 Financial Impact (per 1000 applications):\n",
      "\n",
      "Logistic Regression:\n",
      "Profit from Good Loans: $359,899.33\n",
      "Cost from Missed Good Loans: $220,218.12\n",
      "Cost from Bad Loans: $151,006.71\n",
      "Net Impact: $-11,325.50\n",
      "\n",
      "Random Forest:\n",
      "Profit from Good Loans: $743,288.59\n",
      "Cost from Missed Good Loans: $28,523.49\n",
      "Cost from Bad Loans: $151,006.71\n",
      "Net Impact: $563,758.39\n",
      "\n",
      "XGBoost:\n",
      "Profit from Good Loans: $735,738.26\n",
      "Cost from Missed Good Loans: $32,298.66\n",
      "Cost from Bad Loans: $146,812.08\n",
      "Net Impact: $556,627.52\n",
      "\n",
      "Objective 2 Financial Impact (per 1000 applications):\n",
      "\n",
      "Logistic Regression:\n",
      "Profit from Good Loans: $557,046.98\n",
      "Cost from Missed Good Loans: $121,644.30\n",
      "Cost from Bad Loans: $348,154.36\n",
      "Net Impact: $87,248.32\n",
      "\n",
      "Random Forest:\n",
      "Profit from Good Loans: $561,241.61\n",
      "Cost from Missed Good Loans: $119,546.98\n",
      "Cost from Bad Loans: $16,778.52\n",
      "Net Impact: $424,916.11\n",
      "\n",
      "XGBoost:\n",
      "Profit from Good Loans: $570,469.80\n",
      "Cost from Missed Good Loans: $114,932.89\n",
      "Cost from Bad Loans: $33,557.05\n",
      "Net Impact: $421,979.87\n",
      "Financial impact analysis saved to 'analytics/chapter5/' directory\n"
     ]
    }
   ],
   "source": [
    "# Define costs and benefits for different outcomes\n",
    "# These are hypothetical values - adjust based on business knowledge\n",
    "cost_false_positive = 500  # Cost of rejecting a good customer (lost business opportunity)\n",
    "cost_false_negative = 5000  # Cost of accepting a bad customer (default loss)\n",
    "benefit_true_positive = 0  # Benefit of correctly identifying a bad customer (cost avoidance)\n",
    "benefit_true_negative = 1000  # Benefit of correctly accepting a good customer (profit)\n",
    "\n",
    "def calculate_financial_impact(results):\n",
    "    tn = results['tn']  # Good customers correctly accepted\n",
    "    fp = results['fp']  # Good customers incorrectly rejected\n",
    "    fn = results['fn']  # Bad customers incorrectly accepted\n",
    "    tp = results['tp']  # Bad customers correctly rejected\n",
    "    \n",
    "    # Calculate financial impact\n",
    "    profit_from_good = tn * benefit_true_negative\n",
    "    cost_from_missed_good = fp * cost_false_positive\n",
    "    cost_from_bad = fn * cost_false_negative\n",
    "    benefit_from_avoided_bad = tp * benefit_true_positive\n",
    "    \n",
    "    net_impact = profit_from_good - cost_from_missed_good - cost_from_bad + benefit_from_avoided_bad\n",
    "    \n",
    "    return {\n",
    "        'profit_from_good': profit_from_good,\n",
    "        'cost_from_missed_good': cost_from_missed_good,\n",
    "        'cost_from_bad': cost_from_bad,\n",
    "        'benefit_from_avoided_bad': benefit_from_avoided_bad,\n",
    "        'net_impact': net_impact\n",
    "    }\n",
    "\n",
    "# Objective 1 Financial Impact\n",
    "print(\"\\nObjective 1 Financial Impact (per 1000 applications):\")\n",
    "models = ['Logistic Regression', 'Random Forest', 'XGBoost']\n",
    "results = [lr_obj1_results, rf_obj1_results, xgb_obj1_results]\n",
    "\n",
    "financial_data_obj1 = []\n",
    "for model, model_results in zip(models, results):\n",
    "    impacts = calculate_financial_impact(model_results)\n",
    "    \n",
    "    # Scale to per 1000 applications\n",
    "    total = model_results['tn'] + model_results['fp'] + model_results['fn'] + model_results['tp']\n",
    "    scaling_factor = 1000 / total\n",
    "    \n",
    "    scaled_impacts = {k: v * scaling_factor for k, v in impacts.items()}\n",
    "    \n",
    "    financial_data_obj1.append({\n",
    "        'Model': model,\n",
    "        'Profit from Good Loans': scaled_impacts['profit_from_good'],\n",
    "        'Cost from Missed Good Loans': scaled_impacts['cost_from_missed_good'],\n",
    "        'Cost from Bad Loans': scaled_impacts['cost_from_bad'],\n",
    "        'Net Impact': scaled_impacts['net_impact']\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{model}:\")\n",
    "    print(f\"Profit from Good Loans: ${scaled_impacts['profit_from_good']:,.2f}\")\n",
    "    print(f\"Cost from Missed Good Loans: ${scaled_impacts['cost_from_missed_good']:,.2f}\")\n",
    "    print(f\"Cost from Bad Loans: ${scaled_impacts['cost_from_bad']:,.2f}\")\n",
    "    print(f\"Net Impact: ${scaled_impacts['net_impact']:,.2f}\")\n",
    "\n",
    "# Objective 2 Financial Impact\n",
    "print(\"\\nObjective 2 Financial Impact (per 1000 applications):\")\n",
    "results = [lr_obj2_results, rf_obj2_results, xgb_obj2_results]\n",
    "\n",
    "financial_data_obj2 = []\n",
    "for model, model_results in zip(models, results):\n",
    "    impacts = calculate_financial_impact(model_results)\n",
    "    \n",
    "    # Scale to per 1000 applications\n",
    "    total = model_results['tn'] + model_results['fp'] + model_results['fn'] + model_results['tp']\n",
    "    scaling_factor = 1000 / total\n",
    "    \n",
    "    scaled_impacts = {k: v * scaling_factor for k, v in impacts.items()}\n",
    "    \n",
    "    financial_data_obj2.append({\n",
    "        'Model': model,\n",
    "        'Profit from Good Loans': scaled_impacts['profit_from_good'],\n",
    "        'Cost from Missed Good Loans': scaled_impacts['cost_from_missed_good'],\n",
    "        'Cost from Bad Loans': scaled_impacts['cost_from_bad'],\n",
    "        'Net Impact': scaled_impacts['net_impact']\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{model}:\")\n",
    "    print(f\"Profit from Good Loans: ${scaled_impacts['profit_from_good']:,.2f}\")\n",
    "    print(f\"Cost from Missed Good Loans: ${scaled_impacts['cost_from_missed_good']:,.2f}\")\n",
    "    print(f\"Cost from Bad Loans: ${scaled_impacts['cost_from_bad']:,.2f}\")\n",
    "    print(f\"Net Impact: ${scaled_impacts['net_impact']:,.2f}\")\n",
    "\n",
    "# Save financial analysis results to CSV\n",
    "pd.DataFrame(financial_data_obj1).to_csv('analytics/chapter5/financial_impact_obj1.csv', index=False)\n",
    "pd.DataFrame(financial_data_obj2).to_csv('analytics/chapter5/financial_impact_obj2.csv', index=False)\n",
    "\n",
    "# Bar chart showing net impact by model for both objectives\n",
    "plt.figure(figsize=(12, 6))\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "net_impact_obj1 = [data['Net Impact'] for data in financial_data_obj1]\n",
    "net_impact_obj2 = [data['Net Impact'] for data in financial_data_obj2]\n",
    "\n",
    "plt.bar(x - width/2, net_impact_obj1, width, label='Objective 1')\n",
    "plt.bar(x + width/2, net_impact_obj2, width, label='Objective 2')\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Net Impact ($)')\n",
    "plt.title('Financial Impact by Model and Objective (per 1000 applications)')\n",
    "plt.xticks(x, models)\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(net_impact_obj1):\n",
    "    plt.text(i - width/2, v + (0.05 * max(net_impact_obj1 + net_impact_obj2)), \n",
    "             f\"${v:,.0f}\", ha='center')\n",
    "    \n",
    "for i, v in enumerate(net_impact_obj2):\n",
    "    plt.text(i + width/2, v + (0.05 * max(net_impact_obj1 + net_impact_obj2)), \n",
    "             f\"${v:,.0f}\", ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('analytics/chapter5/financial_impact_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Financial impact analysis saved to 'analytics/chapter5/' directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue\">Final Model Selection & Recommendations</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model by AUC: Random Forest\n",
      "Best model for Objective 1 by financial impact: Random Forest\n",
      "Best model for Objective 2 by financial impact: Random Forest\n",
      "Best model for Objective 1 by good customers accepted: Random Forest\n",
      "Best model for Objective 2 by bad customers identified: Random Forest\n",
      "\n",
      "Recommendations:\n",
      "1. For overall predictive performance: Random Forest\n",
      "2. For Objective 1 (Identify 85% of bad customers): Random Forest\n",
      "3. For Objective 2 (Accept 70% of good customers): Random Forest\n",
      "\n",
      "Analysis complete. All results, visualizations, and recommendations have been saved to the 'analytics/' directory.\n"
     ]
    }
   ],
   "source": [
    "# Combine all metrics for comparison\n",
    "metrics_data = {\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'XGBoost'],\n",
    "    'AUC': [auc_lr, auc_rf, auc_xgb],\n",
    "    \n",
    "    # Objective 1 metrics\n",
    "    'Obj1_Threshold': [lr_obj1_results['threshold'], rf_obj1_results['threshold'], xgb_obj1_results['threshold']],\n",
    "    'Obj1_Bad_Identified (%)': [lr_obj1_results['recall_bad']*100, rf_obj1_results['recall_bad']*100, xgb_obj1_results['recall_bad']*100],\n",
    "    'Obj1_Good_Accepted (%)': [lr_obj1_results['recall_good']*100, rf_obj1_results['recall_good']*100, xgb_obj1_results['recall_good']*100],\n",
    "    'Obj1_Accuracy (%)': [lr_obj1_results['accuracy']*100, rf_obj1_results['accuracy']*100, xgb_obj1_results['accuracy']*100],\n",
    "    'Obj1_Net_Impact ($)': [data['Net Impact'] for data in financial_data_obj1],\n",
    "    \n",
    "    # Objective 2 metrics\n",
    "    'Obj2_Threshold': [lr_obj2_results['threshold'], rf_obj2_results['threshold'], xgb_obj2_results['threshold']],\n",
    "    'Obj2_Bad_Identified (%)': [lr_obj2_results['recall_bad']*100, rf_obj2_results['recall_bad']*100, xgb_obj2_results['recall_bad']*100],\n",
    "    'Obj2_Good_Accepted (%)': [lr_obj2_results['recall_good']*100, rf_obj2_results['recall_good']*100, xgb_obj2_results['recall_good']*100],\n",
    "    'Obj2_Accuracy (%)': [lr_obj2_results['accuracy']*100, rf_obj2_results['accuracy']*100, xgb_obj2_results['accuracy']*100],\n",
    "    'Obj2_Net_Impact ($)': [data['Net Impact'] for data in financial_data_obj2],\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "metrics_df.to_csv('analytics/chapter5/model_comparison_summary.csv', index=False)\n",
    "\n",
    "# Identify best models based on different criteria\n",
    "best_auc_model = metrics_df.loc[metrics_df['AUC'].idxmax(), 'Model']\n",
    "best_obj1_financial_model = metrics_df.loc[metrics_df['Obj1_Net_Impact ($)'].idxmax(), 'Model']\n",
    "best_obj2_financial_model = metrics_df.loc[metrics_df['Obj2_Net_Impact ($)'].idxmax(), 'Model']\n",
    "best_obj1_good_accepted_model = metrics_df.loc[metrics_df['Obj1_Good_Accepted (%)'].idxmax(), 'Model']\n",
    "best_obj2_bad_identified_model = metrics_df.loc[metrics_df['Obj2_Bad_Identified (%)'].idxmax(), 'Model']\n",
    "\n",
    "print(\"\\nBest model by AUC:\", best_auc_model)\n",
    "print(\"Best model for Objective 1 by financial impact:\", best_obj1_financial_model)\n",
    "print(\"Best model for Objective 2 by financial impact:\", best_obj2_financial_model)\n",
    "print(\"Best model for Objective 1 by good customers accepted:\", best_obj1_good_accepted_model)\n",
    "print(\"Best model for Objective 2 by bad customers identified:\", best_obj2_bad_identified_model)\n",
    "\n",
    "# Generate recommendations based on the results\n",
    "print(\"\\nRecommendations:\")\n",
    "print(f\"1. For overall predictive performance: {best_auc_model}\")\n",
    "print(f\"2. For Objective 1 (Identify 85% of bad customers): {best_obj1_financial_model}\")\n",
    "print(f\"3. For Objective 2 (Accept 70% of good customers): {best_obj2_financial_model}\")\n",
    "\n",
    "# Create a text file with a summary of recommendations\n",
    "with open('analytics/chapter5/recommendations.txt', 'w') as f:\n",
    "    f.write(\"Credit Scoring Model Recommendations\\n\")\n",
    "    f.write(\"===================================\\n\\n\")\n",
    "    \n",
    "    f.write(\"Model Performance Summary:\\n\")\n",
    "    f.write(f\"- Best model by AUC: {best_auc_model}\\n\")\n",
    "    f.write(f\"- Best model for Objective 1 by financial impact: {best_obj1_financial_model}\\n\")\n",
    "    f.write(f\"- Best model for Objective 2 by financial impact: {best_obj2_financial_model}\\n\\n\")\n",
    "    \n",
    "    f.write(\"Key Business Recommendations:\\n\")\n",
    "    \n",
    "    # Objective 1 recommendation\n",
    "    obj1_model = best_obj1_financial_model\n",
    "    obj1_idx = metrics_df[metrics_df['Model'] == obj1_model].index[0]\n",
    "    obj1_threshold = metrics_df.loc[obj1_idx, 'Obj1_Threshold']\n",
    "    obj1_bad_id = metrics_df.loc[obj1_idx, 'Obj1_Bad_Identified (%)']\n",
    "    obj1_good_accept = metrics_df.loc[obj1_idx, 'Obj1_Good_Accepted (%)']\n",
    "    obj1_impact = metrics_df.loc[obj1_idx, 'Obj1_Net_Impact ($)']\n",
    "    \n",
    "    f.write(f\"1. For Risk-Averse Strategy (Objective 1):\\n\")\n",
    "    f.write(f\"   - Implement {obj1_model} with threshold {obj1_threshold:.3f}\\n\")\n",
    "    f.write(f\"   - This identifies {obj1_bad_id:.2f}% of bad loans while accepting {obj1_good_accept:.2f}% of good loans\\n\")\n",
    "    f.write(f\"   - Estimated financial impact: ${obj1_impact:,.2f} per 1000 applications\\n\\n\")\n",
    "    \n",
    "    # Objective 2 recommendation\n",
    "    obj2_model = best_obj2_financial_model\n",
    "    obj2_idx = metrics_df[metrics_df['Model'] == obj2_model].index[0]\n",
    "    obj2_threshold = metrics_df.loc[obj2_idx, 'Obj2_Threshold']\n",
    "    obj2_bad_id = metrics_df.loc[obj2_idx, 'Obj2_Bad_Identified (%)']\n",
    "    obj2_good_accept = metrics_df.loc[obj2_idx, 'Obj2_Good_Accepted (%)']\n",
    "    obj2_impact = metrics_df.loc[obj2_idx, 'Obj2_Net_Impact ($)']\n",
    "    \n",
    "    f.write(f\"2. For Growth-Oriented Strategy (Objective 2):\\n\")\n",
    "    f.write(f\"   - Implement {obj2_model} with threshold {obj2_threshold:.3f}\\n\")\n",
    "    f.write(f\"   - This accepts {obj2_good_accept:.2f}% of good loans while identifying {obj2_bad_id:.2f}% of bad loans\\n\")\n",
    "    f.write(f\"   - Estimated financial impact: ${obj2_impact:,.2f} per 1000 applications\\n\\n\")\n",
    "    \n",
    "    # Most important variables\n",
    "    f.write(\"Most Important Variables for Credit Scoring:\\n\")\n",
    "    for i in range(min(5, len(indices))):\n",
    "        if i < len(feature_names_encoded):\n",
    "            f.write(f\"   {i+1}. {feature_names_encoded[indices[i]]}\\n\")\n",
    "    \n",
    "    f.write(\"\\nImplementation Considerations:\\n\")\n",
    "    f.write(\"- The selected threshold balances risk and acceptance rates based on business objectives\\n\")\n",
    "    f.write(\"- Monitor model performance over time and recalibrate as needed\\n\")\n",
    "    f.write(\"- Consider implementing a phased rollout to validate model performance in production\\n\")\n",
    "    f.write(\"- Regular model updates recommended as customer behavior patterns change\\n\")\n",
    "\n",
    "print(\"\\nAnalysis complete. All results, visualizations, and recommendations have been saved to the 'analytics/' directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
